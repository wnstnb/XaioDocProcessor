{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gemini_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'form_number': FieldInfo(annotation=str, required=True, description='The Form Number'),\n",
       " 'tax_year': FieldInfo(annotation=str, required=True, description='The tax year of this form'),\n",
       " 'primary_first_name': FieldInfo(annotation=str, required=True, description='The first name of the primary tax payer'),\n",
       " 'primary_last_name': FieldInfo(annotation=str, required=True, description='The last name of the primary tax payer'),\n",
       " 'primary_ssn_last_4': FieldInfo(annotation=str, required=True, description='Only the last 4 digits of the SSN number of the primary tax payer.'),\n",
       " 'spouse_first_name': FieldInfo(annotation=str, required=True, description='The first name of the spouse. If not provided, please return an empty string.'),\n",
       " 'spouse_last_name': FieldInfo(annotation=str, required=True, description='The first name of the spouse. If not provided, please return an empty string.'),\n",
       " 'spouse_ssn_last_4': FieldInfo(annotation=str, required=True, description='Only the last 4 digits of the SSN of the spouse. If not provided, please return an empty string.'),\n",
       " 'full_address': FieldInfo(annotation=str, required=True, description='The city, state, zip of the taxpayer.'),\n",
       " 'w2_wages': FieldInfo(annotation=str, required=True, description='The total amount from Form W2 on line 1a. May be empty. Return an empty string if no values found on line.'),\n",
       " 'agi': FieldInfo(annotation=str, required=True, description='Adjusted gross income for the year. May be empty. Return an empty string if no values found on line.')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1040_p1.model_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('documents.db')\n",
    "\n",
    "# List of unique filenames\n",
    "query = '''\n",
    "select distinct filename from pages order by created_at desc\n",
    "'''\n",
    "all_files = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acord_28_2025_02_09_102520_906.pdf', '25-GL.pdf',\n",
       "       'ACORD25TEST.png', 'test_sched_c.pdf', 'testacord25.pdf',\n",
       "       'g217064g51y66.jpg', '1120S_bal_sheet_2024_12_27_085143_649.pdf',\n",
       "       'Merged PDF File.pdf', '1065_k1_2024_12_27_085231_070.pdf',\n",
       "       'drivers_license_test.pdf', 'RFD 2022 TAX RETURN.pdf'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files['filename'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 'RFD 2022 TAX RETURN.pdf' # all_files['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinct list of files already uploadeded\n",
    "# df_pages, df_extracted, df_info\n",
    "query = f'''\n",
    "select * from pages\n",
    "where filename = '{ex}'\n",
    "'''\n",
    "df_pages = pd.read_sql_query(query, conn)\n",
    "\n",
    "query = f'''\n",
    "select p.filename base_file, e2.* from extracted2 e2 \n",
    "join (select filename, preprocessed from pages) p on e2.filename = p.preprocessed\n",
    "where p.filename = '{ex}'\n",
    "'''\n",
    "df_extracted = pd.read_sql_query(query, conn)\n",
    "\n",
    "query = f'''\n",
    "select p.filename base_file, i.* from call_info i \n",
    "join (select filename, preprocessed from pages) p on i.filename = p.preprocessed\n",
    "where p.filename = '{ex}'\n",
    "'''\n",
    "df_info = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_file</th>\n",
       "      <th>filename</th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>page_label</th>\n",
       "      <th>page_score</th>\n",
       "      <th>page_num</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RFD 2022 TAX RETURN.pdf</td>\n",
       "      <td>debug_images\\RFD 2022 TAX RETURN\\page_6\\prepro...</td>\n",
       "      <td>business_name</td>\n",
       "      <td>RAINFLOW DEVELOPMENTS, LLC</td>\n",
       "      <td>business_license</td>\n",
       "      <td>0.629119</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-02-17 23:43:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RFD 2022 TAX RETURN.pdf</td>\n",
       "      <td>debug_images\\RFD 2022 TAX RETURN\\page_6\\prepro...</td>\n",
       "      <td>current_standing</td>\n",
       "      <td></td>\n",
       "      <td>business_license</td>\n",
       "      <td>0.629119</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-02-17 23:43:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RFD 2022 TAX RETURN.pdf</td>\n",
       "      <td>debug_images\\RFD 2022 TAX RETURN\\page_11\\prepr...</td>\n",
       "      <td>business_name</td>\n",
       "      <td>RAINFLOW DEVELOPMENTS, LLC</td>\n",
       "      <td>1065_p1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-02-17 23:43:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RFD 2022 TAX RETURN.pdf</td>\n",
       "      <td>debug_images\\RFD 2022 TAX RETURN\\page_11\\prepr...</td>\n",
       "      <td>city_state</td>\n",
       "      <td>Los Banos, CA 93635</td>\n",
       "      <td>1065_p1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-02-17 23:43:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RFD 2022 TAX RETURN.pdf</td>\n",
       "      <td>debug_images\\RFD 2022 TAX RETURN\\page_11\\prepr...</td>\n",
       "      <td>cost_of_goods_sold</td>\n",
       "      <td></td>\n",
       "      <td>1065_p1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-02-17 23:43:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>RFD 2022 TAX RETURN.pdf</td>\n",
       "      <td>debug_images\\RFD 2022 TAX RETURN\\page_91\\prepr...</td>\n",
       "      <td>shareholder_name</td>\n",
       "      <td>Raaj V Desor</td>\n",
       "      <td>1065_k1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91</td>\n",
       "      <td>2025-02-17 23:43:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>RFD 2022 TAX RETURN.pdf</td>\n",
       "      <td>debug_images\\RFD 2022 TAX RETURN\\page_91\\prepr...</td>\n",
       "      <td>ssn_last_4</td>\n",
       "      <td>9948</td>\n",
       "      <td>1065_k1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91</td>\n",
       "      <td>2025-02-17 23:43:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>RFD 2022 TAX RETURN.pdf</td>\n",
       "      <td>debug_images\\RFD 2022 TAX RETURN\\page_91\\prepr...</td>\n",
       "      <td>tax_year</td>\n",
       "      <td>2022</td>\n",
       "      <td>1065_k1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91</td>\n",
       "      <td>2025-02-17 23:43:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>RFD 2022 TAX RETURN.pdf</td>\n",
       "      <td>debug_images\\RFD 2022 TAX RETURN\\page_92\\prepr...</td>\n",
       "      <td>business_name</td>\n",
       "      <td>RAINFLOW DEVELOPMENTS, LLC</td>\n",
       "      <td>business_license</td>\n",
       "      <td>0.716266</td>\n",
       "      <td>92</td>\n",
       "      <td>2025-02-17 23:43:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>RFD 2022 TAX RETURN.pdf</td>\n",
       "      <td>debug_images\\RFD 2022 TAX RETURN\\page_92\\prepr...</td>\n",
       "      <td>current_standing</td>\n",
       "      <td></td>\n",
       "      <td>business_license</td>\n",
       "      <td>0.716266</td>\n",
       "      <td>92</td>\n",
       "      <td>2025-02-17 23:43:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   base_file  \\\n",
       "0    RFD 2022 TAX RETURN.pdf   \n",
       "1    RFD 2022 TAX RETURN.pdf   \n",
       "2    RFD 2022 TAX RETURN.pdf   \n",
       "3    RFD 2022 TAX RETURN.pdf   \n",
       "4    RFD 2022 TAX RETURN.pdf   \n",
       "..                       ...   \n",
       "211  RFD 2022 TAX RETURN.pdf   \n",
       "212  RFD 2022 TAX RETURN.pdf   \n",
       "213  RFD 2022 TAX RETURN.pdf   \n",
       "214  RFD 2022 TAX RETURN.pdf   \n",
       "215  RFD 2022 TAX RETURN.pdf   \n",
       "\n",
       "                                              filename                 key  \\\n",
       "0    debug_images\\RFD 2022 TAX RETURN\\page_6\\prepro...       business_name   \n",
       "1    debug_images\\RFD 2022 TAX RETURN\\page_6\\prepro...    current_standing   \n",
       "2    debug_images\\RFD 2022 TAX RETURN\\page_11\\prepr...       business_name   \n",
       "3    debug_images\\RFD 2022 TAX RETURN\\page_11\\prepr...          city_state   \n",
       "4    debug_images\\RFD 2022 TAX RETURN\\page_11\\prepr...  cost_of_goods_sold   \n",
       "..                                                 ...                 ...   \n",
       "211  debug_images\\RFD 2022 TAX RETURN\\page_91\\prepr...    shareholder_name   \n",
       "212  debug_images\\RFD 2022 TAX RETURN\\page_91\\prepr...          ssn_last_4   \n",
       "213  debug_images\\RFD 2022 TAX RETURN\\page_91\\prepr...            tax_year   \n",
       "214  debug_images\\RFD 2022 TAX RETURN\\page_92\\prepr...       business_name   \n",
       "215  debug_images\\RFD 2022 TAX RETURN\\page_92\\prepr...    current_standing   \n",
       "\n",
       "                          value        page_label  page_score  page_num  \\\n",
       "0    RAINFLOW DEVELOPMENTS, LLC  business_license    0.629119         6   \n",
       "1                                business_license    0.629119         6   \n",
       "2    RAINFLOW DEVELOPMENTS, LLC           1065_p1    1.000000        11   \n",
       "3           Los Banos, CA 93635           1065_p1    1.000000        11   \n",
       "4                                         1065_p1    1.000000        11   \n",
       "..                          ...               ...         ...       ...   \n",
       "211                Raaj V Desor           1065_k1    1.000000        91   \n",
       "212                        9948           1065_k1    1.000000        91   \n",
       "213                        2022           1065_k1    1.000000        91   \n",
       "214  RAINFLOW DEVELOPMENTS, LLC  business_license    0.716266        92   \n",
       "215                              business_license    0.716266        92   \n",
       "\n",
       "              created_at  \n",
       "0    2025-02-17 23:43:55  \n",
       "1    2025-02-17 23:43:55  \n",
       "2    2025-02-17 23:43:55  \n",
       "3    2025-02-17 23:43:55  \n",
       "4    2025-02-17 23:43:55  \n",
       "..                   ...  \n",
       "211  2025-02-17 23:43:55  \n",
       "212  2025-02-17 23:43:55  \n",
       "213  2025-02-17 23:43:55  \n",
       "214  2025-02-17 23:43:55  \n",
       "215  2025-02-17 23:43:55  \n",
       "\n",
       "[216 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acord_28_2025_02_09_102520_906.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-GL.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACORD25TEST.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_sched_c.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>testacord25.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g217064g51y66.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1120S_bal_sheet_2024_12_27_085143_649.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Merged PDF File.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1065_k1_2024_12_27_085231_070.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>drivers_license_test.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RFD 2022 TAX RETURN.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename\n",
       "0          acord_28_2025_02_09_102520_906.pdf\n",
       "1                                   25-GL.pdf\n",
       "2                             ACORD25TEST.png\n",
       "3                            test_sched_c.pdf\n",
       "4                             testacord25.pdf\n",
       "5                           g217064g51y66.jpg\n",
       "6   1120S_bal_sheet_2024_12_27_085143_649.pdf\n",
       "7                         Merged PDF File.pdf\n",
       "8           1065_k1_2024_12_27_085231_070.pdf\n",
       "9                    drivers_license_test.pdf\n",
       "10                    RFD 2022 TAX RETURN.pdf"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'preprocessed', 'page_number', 'image_width',\n",
       "       'image_height', 'lines', 'words', 'bboxes', 'normalized_bboxes',\n",
       "       'tokens', 'words_for_clf', 'processing_time', 'clf_type', 'page_label',\n",
       "       'page_score', 'created_at'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.columns #.groupby('page_label')['page_score'].mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "                \"Extract the structured data from this document. \"\n",
    "                \"If SPII is requested, only return partial data. \"\n",
    "                \"If a field exists but contains no value, return an empty string.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract the structured data from this document. If SPII is requested, only return partial data. If a field exists but contains no value, return an empty string.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from paddleocr import PaddleOCR\n",
    "from transformers import AutoTokenizer, LayoutLMModel\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "# Initialize OCR and LayoutLM\n",
    "ocr = PaddleOCR(use_angle_cls=True, rec=False, lang=\"en\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"impira/layoutlm-document-qa\", add_prefix_space=True)\n",
    "model = LayoutLMModel.from_pretrained(\"impira/layoutlm-document-qa\")\n",
    "model = model.eval()  # Set model to inference mode\n",
    "\n",
    "def extract_features(image_path, question=\"What is in the document?\"):\n",
    "    \"\"\"\n",
    "    Extract words, bounding boxes (normalized), and embeddings from the given image.\n",
    "    Normalization of bounding boxes to a 0-1000 range is performed here.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image.\n",
    "        question (str): A question for tokenization with LayoutLM. This can be a dummy question \n",
    "                        as we primarily need embeddings.\n",
    "                        \n",
    "    Returns:\n",
    "        words (list of str): Detected words from OCR.\n",
    "        normalized_bboxes (list of lists): Normalized bounding boxes in [x1, y1, x2, y2] format.\n",
    "        embeddings (np.ndarray): Token embeddings from LayoutLM.\n",
    "    \"\"\"\n",
    "    # Step 1: Run PaddleOCR on the image\n",
    "    ocr_results = ocr.ocr(image_path, cls=True)[0]\n",
    "\n",
    "    # Extract words and bounding boxes\n",
    "    words = [line[1][0] for line in ocr_results]\n",
    "    boxes = [line[0] for line in ocr_results]\n",
    "\n",
    "    # Convert quadrilateral OCR boxes to rectangular bounding boxes\n",
    "    bboxes = []\n",
    "    for box in boxes:\n",
    "        x1 = min(point[0] for point in box)\n",
    "        y1 = min(point[1] for point in box)\n",
    "        x2 = max(point[0] for point in box)\n",
    "        y2 = max(point[1] for point in box)\n",
    "        bboxes.append([x1, y1, x2, y2])\n",
    "\n",
    "    # Load image to get dimensions and normalize bboxes\n",
    "    image = Image.open(image_path)\n",
    "    image_width, image_height = image.size\n",
    "    normalized_bboxes = [\n",
    "        [\n",
    "            int((x1 / image_width) * 1000),\n",
    "            int((y1 / image_height) * 1000),\n",
    "            int((x2 / image_width) * 1000),\n",
    "            int((y2 / image_height) * 1000),\n",
    "        ]\n",
    "        for (x1, y1, x2, y2) in bboxes\n",
    "    ]\n",
    "\n",
    "    # Step 3: Tokenize question and words for LayoutLM\n",
    "    encoding = tokenizer(\n",
    "        question.split(),\n",
    "        words,\n",
    "        is_split_into_words=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    # Align bounding boxes with tokens\n",
    "    word_ids = encoding.word_ids(0)\n",
    "    bbox = []\n",
    "    for i, s, w in zip(encoding.input_ids[0], encoding.sequence_ids(0), word_ids):\n",
    "        if s == 1 and w is not None:\n",
    "            bbox.append(normalized_bboxes[w])\n",
    "        elif i == tokenizer.sep_token_id:\n",
    "            bbox.append([1000] * 4)\n",
    "        else:\n",
    "            bbox.append([0] * 4)\n",
    "\n",
    "    encoding[\"bbox\"] = torch.tensor([bbox])\n",
    "\n",
    "    # Move encoding to model device if needed\n",
    "    # If model is on CPU, this is not strictly necessary\n",
    "    params = {k: v.to(model.device) for k, v in encoding.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**params)\n",
    "    embeddings = outputs.last_hidden_state[0].cpu().numpy()\n",
    "\n",
    "    return words, normalized_bboxes, embeddings\n",
    "\n",
    "def build_template_database(base_dir='clf_images'):\n",
    "    \"\"\"\n",
    "    Traverse the directory structure:\n",
    "    clf_images/\n",
    "       label1/\n",
    "         base/\n",
    "           template1.png\n",
    "           template2.png\n",
    "       label2/\n",
    "         base/\n",
    "           template1.png\n",
    "    ...\n",
    "    \n",
    "    Extract features for each template image and store in a dictionary:\n",
    "    \n",
    "    template_db = {\n",
    "      'label_name': [\n",
    "         {\n",
    "           'filename': 'template_image_name.png',\n",
    "           'words': [...],\n",
    "           'bboxes': [...],\n",
    "           'embeddings': np.array([...])\n",
    "         },\n",
    "         ...\n",
    "      ],\n",
    "      ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    template_db = {}\n",
    "    for label_name in os.listdir(base_dir):\n",
    "        label_path = os.path.join(base_dir, label_name)\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "        base_path = os.path.join(label_path, 'base')\n",
    "        if not os.path.exists(base_path):\n",
    "            continue\n",
    "        \n",
    "        templates = []\n",
    "        for fname in os.listdir(base_path):\n",
    "            if fname.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                image_path = os.path.join(base_path, fname)\n",
    "                words, bboxes, embeddings = extract_features(image_path)\n",
    "                templates.append({\n",
    "                    'filename': fname,\n",
    "                    'words': words,\n",
    "                    'bboxes': bboxes,\n",
    "                    'embeddings': embeddings\n",
    "                })\n",
    "        if templates:\n",
    "            template_db[label_name] = templates\n",
    "\n",
    "    # Save the template database for future use\n",
    "    with open('template_db.pkl', 'wb') as f:\n",
    "        pickle.dump(template_db, f)\n",
    "\n",
    "    return template_db\n",
    "\n",
    "def load_template_database(db_path='template_db.pkl'):\n",
    "    with open(db_path, 'rb') as f:\n",
    "        template_db = pickle.load(f)\n",
    "    return template_db\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "def semantic_similarity(emb1, emb2):\n",
    "    \"\"\"\n",
    "    Compute semantic similarity by comparing only the minimum number of embeddings\n",
    "    between the two sets. This avoids issues caused by differing lengths.\n",
    "\n",
    "    Args:\n",
    "        emb1 (np.ndarray): Embeddings for the first set of tokens, shape (N1, D).\n",
    "        emb2 (np.ndarray): Embeddings for the second set of tokens, shape (N2, D).\n",
    "\n",
    "    Returns:\n",
    "        float: Semantic similarity score.\n",
    "    \"\"\"\n",
    "    # Determine the minimum length\n",
    "    min_len = min(len(emb1), len(emb2))\n",
    "\n",
    "    # Truncate embeddings to the minimum length\n",
    "    emb1_trimmed = emb1[:min_len]\n",
    "    emb2_trimmed = emb2[:min_len]\n",
    "\n",
    "    # Compute cosine similarity on the trimmed embeddings\n",
    "    avg_emb1 = np.mean(emb1_trimmed, axis=0)\n",
    "    avg_emb2 = np.mean(emb2_trimmed, axis=0)\n",
    "    sim = np.dot(avg_emb1, avg_emb2) / (np.linalg.norm(avg_emb1) * np.linalg.norm(avg_emb2) + 1e-10)\n",
    "\n",
    "    return sim\n",
    "\n",
    "\n",
    "def structural_similarity(bboxes1, bboxes2):\n",
    "    \"\"\"\n",
    "    Compute a structural similarity score based on bounding boxes.\n",
    "    Simple heuristic:\n",
    "    - Compare corresponding boxes (up to the min length).\n",
    "    - Compute Euclidean distances, then convert to similarity.\n",
    "    \"\"\"\n",
    "    min_len = min(len(bboxes1), len(bboxes2))\n",
    "    b1 = np.array(bboxes1[:min_len])\n",
    "    b2 = np.array(bboxes2[:min_len])\n",
    "    # Euclidean distances\n",
    "    dists = np.sqrt(np.sum((b1 - b2)**2, axis=1))\n",
    "    # Convert distance to similarity: sim = 1/(1+dist)\n",
    "    similarities = 1 / (1 + dists)\n",
    "    return float(np.mean(similarities))\n",
    "\n",
    "def compare_image_to_templates(image_path, template_db):\n",
    "    \"\"\"\n",
    "    Given a new image, extract features and compare them to each template in the database.\n",
    "    Return the best-matching label, the highest score, and a dictionary of all scores.\n",
    "\n",
    "    Score is defined as min(semantic_similarity, structural_similarity) as per user request.\n",
    "\n",
    "    Returns:\n",
    "        best_label (str): The label with the highest final score.\n",
    "        best_score (float): The highest final score.\n",
    "        all_scores (dict): A dictionary where keys are labels, and values are lists of dicts:\n",
    "                           [\n",
    "                             {\n",
    "                               'filename': <str>,\n",
    "                               'sem_sim': <float>,\n",
    "                               'struc_sim': <float>,\n",
    "                               'final_score': <float>\n",
    "                             },\n",
    "                             ...\n",
    "                           ]\n",
    "    \"\"\"\n",
    "    words, bboxes, embeddings = extract_features(image_path)\n",
    "    best_score = -float('inf')\n",
    "    best_label = None\n",
    "    all_scores = {}\n",
    "\n",
    "    for label, templates in template_db.items():\n",
    "        label_scores = []\n",
    "        for t in templates:\n",
    "            sem_sim = semantic_similarity(embeddings, t['embeddings'])\n",
    "            struc_sim = structural_similarity(bboxes, t['bboxes'])\n",
    "            final_score = min(sem_sim, struc_sim)\n",
    "\n",
    "            # Record the details for this template\n",
    "            template_result = {\n",
    "                'filename': t['filename'],\n",
    "                'sem_sim': sem_sim,\n",
    "                'struc_sim': struc_sim,\n",
    "                'final_score': final_score\n",
    "            }\n",
    "            label_scores.append(template_result)\n",
    "\n",
    "            # Check if this is the best score so far\n",
    "            if final_score > best_score:\n",
    "                best_score = final_score\n",
    "                best_label = label\n",
    "\n",
    "        all_scores[label] = label_scores\n",
    "\n",
    "    return best_label, best_score, all_scores\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example usage:\n",
    "#     # 1. Build the template database once\n",
    "#     # template_db = build_template_database('clf_images')\n",
    "\n",
    "#     # Or load it if already built\n",
    "#     template_db = load_template_database('template_db.pkl')\n",
    "\n",
    "#     # 2. Classify a new image\n",
    "#     test_image = r'test_pages\\passport_example.png'\n",
    "#     label, score, all_scores = compare_image_to_templates(test_image, template_db)\n",
    "#     print(f\"Predicted label: {label}, Score: {score}\")\n",
    "#     print(all_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_db = load_template_database('template_db.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_db.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = r'test_pages\\passport_example.png'\n",
    "label, score, all_scores = compare_image_to_templates(test_image, template_db)\n",
    "print(f\"Predicted label: {label}, Score: {score}\")\n",
    "print(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Tier Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\form-sage\\.venv310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Projects\\form-sage\\.venv310\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wband\\.cache\\huggingface\\hub\\models--deepseek-ai--DeepSeek-R1-Distill-Llama-8B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading shards: 100%|██████████| 2/2 [06:21<00:00, 190.92s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]\n",
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Projects\\form-sage\\.venv310\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:566: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the text below, determine whether the document is one of the following: lease_document, certificate_of_good_standing, or business_license. If it is none of these, respond 'None'.\n",
      "\n",
      "Text: This agreement is between... and.... It is a lease agreement for the property located at... The parties agree to rent the property for the amount of... per month. This lease is for a term of... months. The lessees are responsible for paying all utilities and taxes. The\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"  # Replace with your chosen model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Create inference pipeline\n",
    "classifier = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Define prompt\n",
    "text = \"Based on the text below, determine whether the document is one of the following: lease_document, certificate_of_good_standing, or business_license. If it is none of these, respond 'None'.\\n\\nText: This agreement is between...\"\n",
    "response = classifier(text, max_length=100, num_return_sequences=1)\n",
    "\n",
    "print(response[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('documents.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to show all tables\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sqlite3\n",
    "\n",
    "def recreate_extracted_table():\n",
    "    conn = sqlite3.connect('documents.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Drop the existing extracted table\n",
    "    cursor.execute('DROP TABLE IF EXISTS extracted')\n",
    "    \n",
    "    # Recreate the extracted table with the desired schema\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE extracted (\n",
    "            key TEXT,\n",
    "            label TEXT,\n",
    "            label_bbox TEXT,\n",
    "            label_confidence REAL,\n",
    "            value TEXT,\n",
    "            value_bbox TEXT,\n",
    "            value_confidence REAL,\n",
    "            page_num INTEGER,\n",
    "            annotated_image_path TEXT,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Call the function to recreate the table\n",
    "recreate_extracted_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"select * from pages\", conn)\n",
    "# df = df.loc[df['filename'].str.contains('dl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preprocessed    debug_images\\drivers_license_test\\page_1\\prepr...\n",
       "lines           [\"NEW YORK\", \"DRIVER\", \"Courtesy of Governor E...\n",
       "Name: 98, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[98,['preprocessed','lines']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = eval(df['words_for_clf'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = df['preprocessed'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funfun():\n",
    "    return 1,2,3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = funfun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if t:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d,e = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fallback Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\form-sage\\.venv310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel, pipeline\n",
    "from PIL import Image\n",
    "\n",
    "# Load models\n",
    "text_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "image_model = CLIPModel.from_pretrained(\"zer0int/CLIP-GmP-ViT-L-14\")\n",
    "image_processor = CLIPProcessor.from_pretrained(\"zer0int/CLIP-GmP-ViT-L-14\")\n",
    "\n",
    "# Define labels (candidate classes)\n",
    "# Align values\n",
    "fallback_labels = [\n",
    "    \"Drivers License\", \n",
    "    \"Passport\", \n",
    "    \"Lease Document\", \n",
    "    \"Certificate of Good Standing\", \n",
    "    \"Business License\"\n",
    "]\n",
    "\n",
    "# Text-Based Classification\n",
    "def classify_using_text(text, labels, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Classify document using text-based zero-shot classification.\n",
    "    \"\"\"\n",
    "    result = text_classifier(text, candidate_labels=labels)\n",
    "    all_scores = result[\"scores\"]\n",
    "    best_label, best_score = result[\"labels\"][0], result[\"scores\"][0]\n",
    "    if best_score >= threshold:\n",
    "        return best_label, best_score, None, all_scores, 'text_clf'\n",
    "    return None\n",
    "\n",
    "# Image-Based Classification\n",
    "def classify_using_image(image_path, labels, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Classify document using image-based zero-shot classification.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    inputs = image_processor(text=labels, images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = image_model(**inputs)\n",
    "    probs = outputs.logits_per_image.softmax(dim=1)  # Image-text similarity scores\n",
    "    all_scores = {l: p.item() for l, p in zip(labels, probs[0])}\n",
    "    best_label = labels[probs.argmax()]\n",
    "    best_score = probs.max().item()\n",
    "    if best_score >= threshold:\n",
    "        return best_label, best_score, None, all_scores, 'image_clf'\n",
    "    return None\n",
    "\n",
    "# Combined Workflow\n",
    "def classify_document(image_path, text, labels, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Classify document using text-based classification first,\n",
    "    and fall back to image-based classification if needed.\n",
    "    \"\"\"\n",
    "    # Step 1: Text-based classification\n",
    "    text_result = classify_using_text(text, labels, threshold)\n",
    "    if text_result:\n",
    "        return text_result\n",
    "\n",
    "    # Step 2: Fallback to image-based classification\n",
    "    image_result = classify_using_image(image_path, labels, threshold)\n",
    "    if image_result:\n",
    "        return image_result\n",
    "\n",
    "    # Step 3: Final fallback\n",
    "    return 'Unknown', 0, None, None, None\n",
    "    # return image_result\n",
    "\n",
    "# # Example Usage\n",
    "# image_path = \"path/to/your/image.jpg\"\n",
    "# text = \"\"\"\n",
    "# This agreement is made on the 1st of January, 2025, between the Landlord and the Tenant. \n",
    "# It outlines the terms and conditions for renting the property located at 123 Main Street.\n",
    "# \"\"\"  # Replace with OCR-extracted text\n",
    "\n",
    "# result = classify_document(img, ' '.join(t for t in list(s)[:100]), fallback_labels)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define labels (candidate classes)\n",
    "fallback_labels = {\n",
    "    \"This is an official drivers license document\":\"drivers_license\", \n",
    "    \"This is a government-issued passport\":\"passport\", \n",
    "    \"This is a legal lease agreement document\":\"lease_document\", \n",
    "    \"This is a certificate verifying good standing for a business\":\"certificate_of_good_standing\", \n",
    "    \"This is an official business license document\":\"business_license\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('This is an official business license document',\n",
       " 0.988182008266449,\n",
       " None,\n",
       " {'This is an official drivers license document': 0.00013374103582464159,\n",
       "  'This is a government-issued passport': 4.688190529122949e-06,\n",
       "  'This is a legal lease agreement document': 1.4443784493778367e-05,\n",
       "  'This is a certificate verifying good standing for a business': 0.011665068566799164,\n",
       "  'This is an official business license document': 0.988182008266449},\n",
       " 'image_clf')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = r'test_pages\\cert_test.png'\n",
    "classify_using_image(img, list(fallback_labels.keys()), threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_100_word_statement():\n",
    "    words = []\n",
    "    while len(words) < 100:\n",
    "        word_length = random.randint(1, 10)\n",
    "        word = ''.join(random.choices(string.ascii_lowercase, k=word_length))\n",
    "        words.append(word)\n",
    "    \n",
    "    # Join the words into a single string\n",
    "    statement = ' '.join(words)\n",
    "    \n",
    "    # Ensure the statement is exactly 100 words long\n",
    "    statement_words = statement.split()\n",
    "    if len(statement_words) > 100:\n",
    "        statement_words = statement_words[:100]\n",
    "    \n",
    "    # Truncate the last word if it is too lengthy\n",
    "    if len(statement_words[-1]) > 10:\n",
    "        statement_words[-1] = statement_words[-1][:10]\n",
    "    \n",
    "    return ' '.join(statement_words)\n",
    "\n",
    "# Example usage\n",
    "statement = generate_100_word_statement()\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(list(set(statement.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from fast_processor import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converting pages...: 1it [00:03,  3.96s/it]\n",
      "0it [00:00, ?it/s]Some weights of the model checkpoint at Snowflake/snowflake-arctic-embed-l-v2.0 were not used when initializing XLMRobertaModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "1it [00:01,  1.86s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_pages\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mlease_example.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Projects\\form-sage\\fast_processor.py:821\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(fp)\u001b[0m\n\u001b[0;32m    819\u001b[0m df_pages[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clf_results\n\u001b[0;32m    820\u001b[0m df_pages[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clf_confidence\n\u001b[1;32m--> 821\u001b[0m df_extracted \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextraction_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_pages)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_extracted)\n",
      "File \u001b[1;32mc:\\Projects\\form-sage\\.venv310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Projects\\form-sage\\.venv310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\Projects\\form-sage\\.venv310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "m = main(r'test_pages\\lease_example.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'key1':1, 'key2':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(d.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractor Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import CLIPProcessor, CLIPModel, pipeline\n",
    "from PIL import Image\n",
    "\n",
    "# -----------------------------\n",
    "# Step 0: Define your labels.json content.\n",
    "# In practice, this JSON would be stored on disk and loaded via json.load().\n",
    "# Here, we define it as a dictionary for demonstration.\n",
    "labels_questions = {\n",
    "    \"Drivers License\": [\n",
    "        \"What is the full name of this license holder?\",\n",
    "        \"What US state is this drivers license from?\",\n",
    "        \"What is the expiration date of this license?\"\n",
    "    ],\n",
    "    \"Passport\": [\n",
    "        \"What is the passport number?\",\n",
    "        \"What is the nationality of the passport holder?\",\n",
    "        \"What is the date of issue of the passport?\"\n",
    "    ],\n",
    "    \"Lease Document\": [\n",
    "        \"What is the lease start date?\",\n",
    "        \"What is the monthly rent amount?\",\n",
    "        \"Who is the landlord or lessor?\"\n",
    "    ],\n",
    "    \"Certificate of Good Standing\": [\n",
    "        \"What is the certificate number?\",\n",
    "        \"What is the date of issuance?\",\n",
    "        \"What is the registered company name?\"\n",
    "    ],\n",
    "    \"Business License\": [\n",
    "        \"What is the business license number?\",\n",
    "        \"What is the expiration date of the license?\",\n",
    "        \"What is the name of the business?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Optionally, if you store this on disk as labels.json, you can load it with:\n",
    "# with open(\"labels.json\", \"r\") as f:\n",
    "#     labels_questions = json.load(f)\n",
    "\n",
    "# -----------------------------\n",
    "# Pre-existing fallback labels list\n",
    "fallback_labels = [\n",
    "    \"Drivers License\", \n",
    "    \"Passport\", \n",
    "    \"Lease Document\", \n",
    "    \"Certificate of Good Standing\", \n",
    "    \"Business License\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Load classification models\n",
    "text_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "image_model = CLIPModel.from_pretrained(\"zer0int/CLIP-GmP-ViT-L-14\")\n",
    "image_processor = CLIPProcessor.from_pretrained(\"zer0int/CLIP-GmP-ViT-L-14\")\n",
    "\n",
    "# -----------------------------\n",
    "# Text-Based Classification\n",
    "def classify_using_text(text, labels, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Classify document using text-based zero-shot classification.\n",
    "    \"\"\"\n",
    "    result = text_classifier(text, candidate_labels=labels)\n",
    "    all_scores = result[\"scores\"]\n",
    "    best_label, best_score = result[\"labels\"][0], result[\"scores\"][0]\n",
    "    if best_score >= threshold:\n",
    "        return best_label, best_score, None, all_scores, 'text_clf'\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# Image-Based Classification\n",
    "def classify_using_image(image_path, labels, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Classify document using image-based zero-shot classification.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    inputs = image_processor(text=labels, images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = image_model(**inputs)\n",
    "    probs = outputs.logits_per_image.softmax(dim=1)  # Image-text similarity scores\n",
    "    all_scores = {l: p.item() for l, p in zip(labels, probs[0])}\n",
    "    best_label = labels[probs.argmax()]\n",
    "    best_score = probs.max().item()\n",
    "    if best_score >= threshold:\n",
    "        return best_label, best_score, None, all_scores, 'image_clf'\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# Combined Workflow: Document Classification\n",
    "def classify_document(image_path, text, labels, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Classify document using text-based classification first,\n",
    "    and fall back to image-based classification if needed.\n",
    "    \"\"\"\n",
    "    # Step 1: Text-based classification\n",
    "    text_result = classify_using_text(text, labels, threshold)\n",
    "    if text_result:\n",
    "        return text_result\n",
    "\n",
    "    # Step 2: Fallback to image-based classification\n",
    "    image_result = classify_using_image(image_path, labels, threshold)\n",
    "    if image_result:\n",
    "        return image_result\n",
    "\n",
    "    # Step 3: Final fallback: return Unknown if both methods fail.\n",
    "    return 'Unknown', 0, None, None, None\n",
    "\n",
    "# -----------------------------\n",
    "# Load a QA model for information extraction.\n",
    "qa_pipeline = pipeline(\"document-question-answering\", model=\"impira/layoutlm-document-qa\")\n",
    "\n",
    "from custom_pipeline import layoutlm_paddleocr_pipeline\n",
    "\n",
    "def extract_information(input, doc_label, labels_questions):\n",
    "    \"\"\"\n",
    "    Extracts information from document_text based on the questions\n",
    "    associated with doc_label, returning both answers and confidence scores.\n",
    "    \"\"\"\n",
    "    # Retrieve the list of questions for the document type.\n",
    "    questions = labels_questions.get(doc_label, [])\n",
    "    answers = {}\n",
    "    for question in questions:\n",
    "        result = layoutlm_paddleocr_pipeline(image_path=input, question=question)\n",
    "        # result includes \"answer\" and \"score\"\n",
    "        answers[question] = {\"answer\": result[\"answer\"], \"confidence\": result[\"score\"]}\n",
    "    return answers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document classified as: Drivers License (score: 0.6841147541999817, method: text_clf)\n",
      "Full scores: [0.6841147541999817, 0.25053372979164124, 0.04078324884176254, 0.012909149751067162, 0.011659120209515095]\n",
      "[2025/02/03 21:12:22] ppocr DEBUG: dt_boxes num : 16, elapsed : 0.041593074798583984\n",
      "[2025/02/03 21:12:22] ppocr DEBUG: cls num  : 16, elapsed : 0.017036914825439453\n",
      "[2025/02/03 21:12:22] ppocr DEBUG: rec_res num  : 16, elapsed : 0.15475130081176758\n",
      "[2025/02/03 21:12:22] ppocr DEBUG: dt_boxes num : 16, elapsed : 0.04526019096374512\n",
      "[2025/02/03 21:12:22] ppocr DEBUG: cls num  : 16, elapsed : 0.019980192184448242\n",
      "[2025/02/03 21:12:23] ppocr DEBUG: rec_res num  : 16, elapsed : 0.1740555763244629\n",
      "[2025/02/03 21:12:23] ppocr DEBUG: dt_boxes num : 16, elapsed : 0.0445399284362793\n",
      "[2025/02/03 21:12:23] ppocr DEBUG: cls num  : 16, elapsed : 0.01824164390563965\n",
      "[2025/02/03 21:12:23] ppocr DEBUG: rec_res num  : 16, elapsed : 0.2006824016571045\n",
      "\n",
      "Extracted Information:\n",
      "- What is the full name of this license holder?: NeW YORK (confidence: 0.967)\n",
      "- What US state is this drivers license from?: NeW YORK (confidence: 0.923)\n",
      "- What is the expiration date of this license?: DOB: 2-19-74 (confidence: 0.325)\n"
     ]
    }
   ],
   "source": [
    "# Example usage with your updated snippet:\n",
    "image_path = df.loc[98, ['preprocessed']].values[0]\n",
    "document_text = df.loc[98, ['lines']].values[0]\n",
    "\n",
    "# Step 1: Classify the document.\n",
    "doc_label, score, _, scores_dict, method = classify_document(image_path, document_text, fallback_labels)\n",
    "print(f\"Document classified as: {doc_label} (score: {score}, method: {method})\")\n",
    "print(\"Full scores:\", scores_dict)\n",
    "\n",
    "# Step 2: If classified, extract the relevant information.\n",
    "if doc_label != 'Unknown':\n",
    "    # extracted_data = extract_information(image_path, doc_label, labels_questions)\n",
    "    extracted_data = extract_information(image_path, doc_label, labels_questions)\n",
    "    print(\"\\nExtracted Information:\")\n",
    "    for question, info in extracted_data.items():\n",
    "        print(f\"- {question}: {info['answer']} (confidence: {info['confidence']:.3f})\")\n",
    "else:\n",
    "    print(\"Document classification failed. No extraction performed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytesseract"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
